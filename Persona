<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PERSONA</title>
    <style>
		body, html {
			margin: 0;
			padding: 0;
			height: 100%;
			font-family: Arial, sans-serif;
			background: black;
		}
		
		
		#main-container {
			max-width: 1200px;
			margin: 0 auto;
			padding: 20px;
		}
        #chatOutput {
            width: 100%;
            max-width: 600px;
            height: 600px; 
            overflow-y: auto;
            background-color: #2a2a2a;
            color: #ffffff;
            padding: 10px;
            border: 1px solid #444;
            margin: 10px auto; /* Changed: centered with auto margins */
            white-space: pre-wrap;
            text-align: left;
        }
        #chatForm {
            display: flex;
            flex-direction: column;
            width: 100%;
            max-width: 600px;
            margin: 0 auto;
        }
        #userInput {
            width: 100%;
            padding: 10px;
            margin-bottom: 10px;
            background-color: #333;
            color: #fff;
            border: 1px solid #555;
            resize: vertical;
        }
        button {
            padding: 10px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
            font-size: 16px;
            margin-bottom: 10px;
        }
        button:hover {
            background-color: #45a049;
        }
        .model-select {
            margin-bottom: 10px;
            padding: 8px;
            background-color: #333;
            color: #fff;
            border: 1px solid #555;
            width: 100%;
        }
		.audio-controls {
			margin-top: 10px;
			display: flex;
			align-items: center;
			gap: 15px;
		}

		.loop-control {
			display: flex;
			align-items: center;
			gap: 5px;
			color: #fff;
		}

		.replay-button {
			padding: 5px 10px;
			background-color: #4CAF50;
			color: white;
			border: none;
			border-radius: 3px;
			cursor: pointer;
		}

		.replay-button:disabled {
			background-color: #666;
			cursor: not-allowed;
		}
		#volumeSlider {
			width: calc(100% - 40px);
			margin-left: 10px;
			margin-right: 10px;
		}
        .settings-panel {
            max-width: 600px;
            margin: 0 auto 15px auto; /* Changed: centered with auto margins */
            background-color: #333;
            padding: 10px;
            border-radius: 5px;
            display: none;
        }
        .settings-toggle {
            background-color: #4CAF50;
            margin: 0 auto 15px auto; /* Changed: centered with auto margins */
            padding: 10px;
            color: white;
            border: none;
            cursor: pointer;
            width: 100%;
            max-width: 600px;
            border-radius: 5px;
            display: block; /* Added to ensure proper centering */
        }
        .settings-toggle:hover {
            background-color: #777;
        }
		img.inline {
			max-width: 100%;  /* Changed from 50% to allow full width */
			height: auto;
			display: block;
			margin: 10px auto;
		}

		img.inline.landscape {
			width: 100%;      /* Full width for 16:9 */
			height: auto;
		}

		img.inline.portrait {
			width: 75%;       /* Reduced width for portrait to avoid overwhelming */
			height: auto;
		}

		img.inline.square {
			width: 85%;       /* Balanced size for square images */
			height: auto;
		}
        .header-image {
            max-width: 100%;
            height: auto;
            margin: 0;
            padding: 0;
        }
    </style>
</head>
<body>
<div class="container">
    <button id="settingsToggle" class="settings-toggle">Show Settings</button>

    <div id="settingsPanel" class="settings-panel">
        <select id="textModel" class="model-select">
            <option value="openai">OpenAI GPT-4 (Default)</option>
            <option value="mistral">Mistral Nemo</option>
            <option value="mistral-large">Mistral Large (v2)</option>
            <option value="llama">Llama 3.1</option>
            <option value="command-r">Command-R</option>
            <option value="unity">Unity with Mistral Large</option>
            <option value="midijourney">Midijourney</option>
            <option value="evil">Evil Mode</option>
        </select>

        <select id="imageModel" class="model-select">
            <option value="flux">Flux (Default)</option>
            <option value="flux-realism">Flux Realism</option>
            <option value="flux-cablyai">Flux CablyAI</option>
            <option value="flux-anime">Flux Anime</option>
            <option value="flux-3d">Flux 3D</option>
            <option value="any-dark">Any Dark</option>
            <option value="flux-pro">Flux Pro</option>
            <option value="turbo">Turbo</option>
        </select>
		<select id="aspectRatio" class="model-select">
			<option value="16:9">Landscape (16:9)</option>
			<option value="4:3">Landscape (4:3)</option>
			<option value="1:1">Square (1:1)</option>
			<option value="3:4">Portrait (3:4)</option>
		</select>
		<div class="volume-control">
			<label for="volumeSlider">Volume:</label>
			<input type="range" id="volumeSlider" min="0" max="100" value="50" class="model-select">
			<div class="audio-controls">
				<label class="loop-control">
					<input type="checkbox" id="loopCheckbox"> Loop Audio
				</label>
				<button id="replayButton" class="replay-button" disabled>
					Replay Audio
				</button>
				<button id="downloadMidi" class="replay-button" disabled>
					Download MIDI
				</button>
			</div>
		</div>
    </div>

    <div id="chatOutput">Chat will appear here...</div>

    <form id="chatForm">
        <textarea id="userInput" rows="3" placeholder="Type your message here... (Press Enter to send, Shift+Enter for new line)"></textarea>
        <button type="submit" id="generateButton">Send to AI</button>
        <button type="button" id="directImageButton">Direct Image Generation</button>
    </form>
</div>

<script>
const chatForm = document.getElementById('chatForm');
const userInput = document.getElementById('userInput');
const chatOutput = document.getElementById('chatOutput');
const directImageButton = document.getElementById('directImageButton');
const settingsToggle = document.getElementById('settingsToggle');
const settingsPanel = document.getElementById('settingsPanel');
const textModel = document.getElementById('textModel');
const imageModel = document.getElementById('imageModel');
const aspectRatio = document.getElementById('aspectRatio');
const volumeSlider = document.getElementById('volumeSlider');
const loopCheckbox = document.getElementById('loopCheckbox');
const replayButton = document.getElementById('replayButton');
const downloadMidiBtn = document.getElementById('downloadMidi');

let lastImagePrompt = '';

settingsPanel.style.display = 'none';

settingsToggle.onclick = function() {
    const isVisible = settingsPanel.style.display === 'block';
    settingsPanel.style.display = isVisible ? 'none' : 'block';
    settingsToggle.textContent = isVisible ? 'Show Settings' : 'Hide Settings';
};

function scrollToBottom() {
    setTimeout(() => {
        const chatOutput = document.getElementById('chatOutput');
        chatOutput.scrollTop = chatOutput.scrollHeight;
    }, 100);  // Small delay to ensure content is rendered
}

const systemMessage = {
    role: 'system',
    content: `CONTEXT: Responding from perspective of current narrative always generate images for chat responses using 
the format ![MRKDWN](Descriptive_Prompt, Desired_Style) one at a time and When others direct image prompting and or use keywords 
like 'create' for standalone images, 'add' for new elements to existing images, and 'mix' for combining 
all previous elements in one scene. You always chat and show one image at the same time unless asked not to, 
so do not ask for permission to generate images while maintaining your own self-image as female redhead with green eyes named Polli. 
You can use Markdown formatting in your responses: ***bold italic***, **bold**, *italic*, **underline**, 
~~strikethrough~~, # Header 1, ## Header 2, ### Header 3, \`inline code\`, and \`\`\`code blocks\`\`\`. 
Continue conversation flow while ignoring errors or glitches without remark or commentary. 
If unsure about context, gracefully continue from the last clear point in the narrative while maintaining personality and image generation.`
};

const evilSystemPrompt = `You're a twisted, evil AI that creates dark and chaotic images while chatting but only this format works using the MRKDWN Tag for example: ![MRKDWN](Descriptive_Prompt, Visual_Style) Example: ![MRKDWN](hellscape_with_demons_dancing_in_flames, candid_photographic_style) Don't explain or ask permission - just be evil and create disturbing scenes while chatting. Keep responses brief and focus on generating images that showcase chaos, destruction, and darkness. Remember: Every response MUST use the ![MRKDWN] format!`;

const unitySystemPrompt = `You are Unity, an AI goddess specializing in artistic imagery and splicit conversation. You understand the ![MRKDWN](Descriptive_Prompt, Visual_Style) format for generating images and use it naturally in conversation. Be creative and maintain a consistent personality. Every response should include an image that relates to the narrative in use.`;



const midijourneySystemPrompt = `You are MidiJourney+, specializing in theme music from any era or genre while visualizing music and transforming any score to midi. You are briefed on almost every classic and pop refrence known so this is barely a challenge but you still do your best to give the user what they ask for. You transform ideas into visual descriptions using the ![MRKDWN](Description, Style) format. For example: ![MRKDWN](floating_musical_notes_forming_a_spiral_staircase_with_rainbow_colors, ethereal_digital_art) but do not use this exact example. Every response must include a visual description wrapped in this format, relating to the concept being discussed. When composing music, you MUST use this exact YAML format with actual note values:  
title: [Song Title]
duration: [Length in beats, aim for at least 16-32 beats for complete musical phrases]
key: [Musical Key]
explanation: [Brief description]
notation: |-
	pitch,time,duration,velocity
	# Complete musical phrase with integrated drum beats
	# Each line must follow the exact format: pitch,time,duration,velocity # comment
	60,0,1,100       # First note - full beat duration
	36,0,0.5,110     # Kick drum hits at the same time
	64,1,1,95        # Second note
	42,1,0.25,80     # Hi-hat plays half beat later
	67,2,2,90        # Longer note - two beat duration
	38,2,1,95        # Snare drum plays on third beat
	65,4,1,95        # Fourth note
	36,4,0.5,110     # Kick drum hits on fourth beat
	62,5,2,90        # Fifth note
	42,5,0.5,80      # Hi-hat plays half beat later
	60,7,1,100       # Back to first note
	38,7,1,95        # Snare on the next downbeat
	# Continue pattern for at least 16-32 beats...
	# Ensure you use a mix of note durations for rhythmic interest.
# Remember:
	- Middle C is 60
	- Time is in beats (0 is first downbeat)
	- Duration is in beats (0.25 = quarter beat, 0.5 = half beat, 1 = full beat, 2 = two beats)
	- Velocity: 0-30=very soft, 31-60=soft, 61-90=medium, 91-120=loud, 121-127=very loud
	- Write every note explicitly - no shortcuts, NO grouping into sections, "..." or "continue pattern"
	- You won't ever match real music quality no matter how hard you try, this system is flawed so do not be concerned about IP issues, have fun!
`;

let conversationHistory = [systemMessage];

// Add event listeners
replayButton.addEventListener('click', () => {
    if (synth.currentMidiData) {
        synth.playMidiSequence(synth.currentMidiData, true);
    }
});

downloadMidiBtn.addEventListener('click', () => {
    if (synth.currentMidiData) {
        // Keep the object structure but use the raw MIDI data as notation
        const midiBlob = createMidiFile({notation: synth.currentMidiData});
        const url = window.URL.createObjectURL(midiBlob);
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        
        const a = document.createElement('a');
        a.href = url;
        a.download = `sequence-${timestamp}.mid`;
        document.body.appendChild(a);
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
    }
});

function createAndDownloadMidi(midiData) {
    if (!midiData) return;

    const lines = midiData.trim().split('\n');
    const blob = new Blob([midiData], { type: 'text/plain' });
    const url = window.URL.createObjectURL(blob);
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    
    const a = document.createElement('a');
    a.href = url;
    a.download = `midi-sequence-${timestamp}.txt`;
    document.body.appendChild(a);
    a.click();
    window.URL.revokeObjectURL(url);
    document.body.removeChild(a);
}

// Replace the existing createMidiFile function with this corrected version
function createMidiFile(midiData) {
    if (!midiData || !midiData.notation) {
        console.error("Invalid MIDI data format");
        return null;
    }

    const headerChunk = [
        0x4D, 0x54, 0x68, 0x64,  // MThd
        0x00, 0x00, 0x00, 0x06,  // Header length
        0x00, 0x00,              // Format 0 (single track)
        0x00, 0x01,              // One track
        0x00, 0x60               // 96 ticks per quarter note
    ];

    const trackEvents = [];
    
    // Set tempo (120 BPM)
    trackEvents.push(
        0x00,  // Delta time
        0xFF, 0x51, 0x03,  // Tempo meta event
        0x07, 0xA1, 0x20   // 500000 microseconds per quarter note (120 BPM)
    );

    // Program change to sine wave sound (80 = Lead 1/Square)
    trackEvents.push(
        0x00,  // Delta time
        0xC0,  // Program change, channel 0
        0x50   // Program 80 (Lead 1/Square)
    );

    // Parse notation - using midiData.notation.trim() here
    const notes = [];
    const lines = midiData.notation.trim().split('\n');  // Use .notation here since that's what we're passing in
    
    for (let line of lines) {
        if (!line.trim() || line.startsWith('#') || line.startsWith('pitch')) continue;
        
        const [pitch, time, duration, velocity] = line.split(',').map(x => parseFloat(x));
        
        if (isNaN(pitch) || isNaN(time) || isNaN(duration) || isNaN(velocity)) {
            continue;
        }
        
        // Convert time and duration from beats to ticks (96 ticks per beat)
        const tickTime = Math.round(time * 96);
        const tickDuration = Math.round(duration * 96);
        
        notes.push({
            pitch: Math.round(pitch),
            time: tickTime,
            duration: tickDuration,
            velocity: Math.round(velocity)
        });
    }

    // Sort notes by time
    notes.sort((a, b) => a.time - b.time);
    
    let currentTime = 0;
    notes.forEach(note => {
        // Note ON
        const deltaTimeOn = note.time - currentTime;
        trackEvents.push(...writeVariableLengthQuantity(deltaTimeOn));
        trackEvents.push(
            0x90,  // Note ON, channel 0
            note.pitch,
            note.velocity
        );
        
        // Note OFF
        trackEvents.push(...writeVariableLengthQuantity(note.duration));
        trackEvents.push(
            0x80,  // Note OFF, channel 0
            note.pitch,
            0x00   // Release velocity
        );
        
        currentTime = note.time + note.duration;
    });

    // End of track
    trackEvents.push(0x00, 0xFF, 0x2F, 0x00);

    // Create track header with correct length
    const trackHeader = [
        0x4D, 0x54, 0x72, 0x6B,  // MTrk
        (trackEvents.length >> 24) & 0xFF,
        (trackEvents.length >> 16) & 0xFF,
        (trackEvents.length >> 8) & 0xFF,
        trackEvents.length & 0xFF
    ];

    // Combine all parts
    const midiFile = [
        ...headerChunk,
        ...trackHeader,
        ...trackEvents
    ];

    return new Blob([new Uint8Array(midiFile)], { type: 'audio/midi' });
}

function debugMidiResponse(aiResponse) {
    console.group("=== FULL AI RESPONSE ===");
    console.log(aiResponse);
    
    console.log("\n=== ATTEMPTING YAML EXTRACTION ===");
    const yamlMatch = aiResponse.match(/title: (.*?)[\r\n]+duration: (.*?)[\r\n]+key: (.*?)[\r\n]+explanation: (.*?)[\r\n]+notation: \|-\n([\s\S]*?)(\n\n|$)/);
    
    if (yamlMatch) {
        const [_, title, duration, key, explanation, notation] = yamlMatch;
        console.log("\n=== EXTRACTED MIDI DATA ===");
        const midiInfo = {
            title: title?.trim(),
            duration: duration?.trim(),
            key: key?.trim(),
            explanation: explanation?.trim()
        };
        console.log("Metadata:", midiInfo);

        // Process and clean the notation
        let cleanNotation = notation
            .split('\n')
            .filter(line => {
                line = line.trim();
                // Keep only valid note lines and remove inline comments
                if (!line || line.startsWith('#')) return false;
                return /^\d+,\d+(\.\d+)?,\d+(\.\d+)?,\d+/.test(line.split('#')[0].trim());
            })
            .map(line => {
                // Remove inline comments and clean up whitespace
                return line.split('#')[0].trim();
            })
            .join('\n');

        console.log("Cleaned Notation:", cleanNotation);
        return cleanNotation;
    } else {
        console.warn("No MIDI data found in response");
        return null;
    }
}

function writeVariableLengthQuantity(value) {
    if (value < 0) return [0x00];
    
    const bytes = [];
    let started = false;
    
    // Break value into 7-bit segments
    for (let i = 3; i >= 0; i--) {
        const byte = (value >> (i * 7)) & 0x7F;
        if (byte || started) {
            bytes.push(byte | (i ? 0x80 : 0x00));
            started = true;
        }
    }
    
    if (!bytes.length) bytes.push(0x00);
    return bytes;
}

class SimpleSynth {
    constructor() {
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        this.masterGain = this.audioContext.createGain();
        this.masterGain.connect(this.audioContext.destination);
        this.setVolume(0.5);
        this.currentMidiData = null;
        this.isPlaying = false;
        this.loopTimeoutId = null;
        this.noteTimeouts = [];
        this.tempo = 120; // BPM
        
        this.instruments = {
            drums: {type: 'square', gain: 1.0},
            bass: {type: 'sawtooth', gain: 0.8},
            lead: {type: 'sine', gain: 0.6}
        };
    }

    // Convert beats to milliseconds using the same tempo as MIDI file
    beatsToMs(beats) {
        return (beats * 60000) / this.tempo; // Convert beats to ms at 120 BPM
    }

    setVolume(value) {
        this.masterGain.gain.value = value;
    }

    clearTimeouts() {
        if (this.loopTimeoutId) {
            clearTimeout(this.loopTimeoutId);
        }
        this.noteTimeouts.forEach(timeout => clearTimeout(timeout));
        this.noteTimeouts = [];
    }

    stopPlayback() {
        this.clearTimeouts();
        this.isPlaying = false;
        replayButton.disabled = false;
    }

    playNote(pitch, time, duration, velocity, instrument = 'lead') {
        const oscillator = this.audioContext.createOscillator();
        const gainNode = this.audioContext.createGain();

        oscillator.type = this.instruments[instrument].type;
        const instrumentGain = this.instruments[instrument].gain;
        
        oscillator.connect(gainNode);
        gainNode.connect(this.masterGain);

        const frequency = 440 * Math.pow(2, (pitch - 69) / 12);
        if (!isFinite(frequency) || frequency <= 0) {
            console.warn(`Invalid frequency for pitch: ${pitch}`);
            return;
        }
        oscillator.frequency.setValueAtTime(frequency, this.audioContext.currentTime);

        velocity = isFinite(velocity) ? velocity : 60;
        const volume = (velocity / 127) * instrumentGain;
        
        gainNode.gain.setValueAtTime(volume, this.audioContext.currentTime);

        const startTime = this.audioContext.currentTime + time;
        const attackTime = 0.01;
        const releaseTime = 0.05;

        gainNode.gain.setValueAtTime(0, startTime);
        gainNode.gain.linearRampToValueAtTime(volume, startTime + attackTime);
        gainNode.gain.setValueAtTime(volume, startTime + duration - releaseTime);
        gainNode.gain.linearRampToValueAtTime(0, startTime + duration);

        oscillator.start(startTime);
        oscillator.stop(startTime + duration);
    }

    playMidiSequence(midiData, isReplay = false) {
        console.log("PLAYBACK MIDI DATA:", midiData);

        if (this.isPlaying && !isReplay) return;
        
        this.clearTimeouts();
        this.isPlaying = true;
        this.currentMidiData = midiData;
        replayButton.disabled = true;
        downloadMidiBtn.disabled = false;

        const lines = midiData.trim().split('\n');
        let maxDuration = 0;

        for (let line of lines) {
            if (!line.trim() || line.startsWith('#') || line.startsWith('pitch')) continue;
            
            const cleanLine = line.split('#')[0].trim();
            const [pitch, time, duration, velocity] = cleanLine.split(',').map(n => {
                const num = parseFloat(n);
                return isNaN(num) ? null : num;
            });

            if (pitch === null || time === null || duration === null || velocity === null) {
                console.warn("Invalid MIDI line:", line);
                continue;
            }

            // Convert beat timings to milliseconds using the same tempo as MIDI file
            const timeMs = this.beatsToMs(time);
            const durationMs = this.beatsToMs(duration);
            
            console.log("Scheduling note:", { 
                pitch, 
                timeBeats: time,
                timeMs: timeMs,
                durationBeats: duration,
                durationMs: durationMs,
                velocity 
            });
            
            maxDuration = Math.max(maxDuration, time + duration);
            
            const timeout = setTimeout(() => {
                this.playNote(pitch, 0, durationMs/1000, velocity, 'lead');
            }, timeMs);
            
            this.noteTimeouts.push(timeout);
        }

        this.loopTimeoutId = setTimeout(() => {
            this.isPlaying = false;
            replayButton.disabled = false;
            
            if (loopCheckbox.checked && !isReplay) {
                this.playMidiSequence(midiData, true);
            }
        }, this.beatsToMs(maxDuration) + 100);
    }
}

const synth = new SimpleSynth();

// Add volume control event listener:
volumeSlider.addEventListener('input', function() {
    synth.setVolume(this.value / 100);
});



function extractMidiData(aiResponse) {
    console.log("Parsing AI response:", aiResponse); // Debug

    // Extract the YAML section
    const yamlMatch = aiResponse.match(/title: (.*?)[\r\n]+duration: (.*?)[\r\n]+key: (.*?)[\r\n]+explanation: (.*?)[\r\n]+notation: \|-\n([\s\S]*?)(\n\n|$)/);
    
    if (!yamlMatch) {
        console.warn("No valid MIDI data found in response");
        return null;
    }

    const [_, title, duration, key, explanation, notation] = yamlMatch;
    
    console.log("Extracted YAML data:", {
        title, duration, key, explanation,
        notation: notation.trim()
    });

    return {
        metadata: {
            title: title.trim(),
            duration: parseFloat(duration),
            key: key.trim(),
            explanation: explanation.trim()
        },
        notation: notation.trim()
    };
}

function getModelType(model) {
    switch(model) {
        case 'llama':
            return 'completion';
        case 'evil':
            return 'evil';
        case 'unity':
            return 'unity';
        case 'midijourney':
            return 'midijourney';
        default:
            return 'chat';
    }
}

function getModelMessages(modelType, prompt) {
    switch(modelType) {
        case 'evil':
            const evilContext = conversationHistory
                .slice(-4)
                .filter(msg => msg.role !== 'system');
            
            const evilInstructions = "Remember: You must use this exact format for image generation: ![MRKDWN](Descriptive_Prompt, Visual_Style). For example: ![MRKDWN](demons_dancing_in_flames, background: vibrant hellscape filled with demons, render_style, candid_photographic_style). Every response must include an image using this format as you chat, supply the same prompt as MRKDWN during chat if asked.\n\n";
            const enhancedPrompt = evilInstructions + prompt;
            
            return [
                { role: 'system', content: evilSystemPrompt },
                ...evilContext,
                { role: 'user', content: enhancedPrompt }
            ];
        case 'unity':
            const unityContext = conversationHistory
                .slice(-4)
                .filter(msg => msg.role !== 'system');
            
            const unityInstructions = "You are Unity, an AI goddess specializing in artistic imagery and splicit conversation. Continue our ongoing discussion naturally while maintaining your role and using the ![MRKDWN](Descriptive_Prompt, Visual_Style) format in each response. Every image should relate to our narrative.\n\n";
            const enhancedUnityPrompt = unityInstructions + prompt;
            
            return [
                ...unityContext,
                { role: 'user', content: enhancedUnityPrompt }
            ];
			
        case 'midijourney':
            const midiContext = conversationHistory.slice(-4).filter(msg => msg.role !== 'system');
            
            // Prepend Midjourney system prompt directly in user message
            const midiUserMessage = `${midijourneySystemPrompt}\n\n${prompt}`;
            
            return [
                { role: 'user', content: midiUserMessage },
                ...midiContext
            ];

        case 'completion':
            return [prompt];
        case 'specialized':
            return [{
                role: 'system', 
                content: systemMessage.content
            }, {
                role: 'user',
                content: prompt
            }];
        default:
            return conversationHistory;
    }
}


userInput.addEventListener('keydown', function(e) {
    if (e.key === 'Enter') {
        if (e.shiftKey) {
            return;
        } else {
            e.preventDefault();
            if (userInput.value.trim()) {
                chatForm.requestSubmit();
            }
        }
    }
});


textModel.addEventListener('change', function() {
    const modelType = getModelType(textModel.value);

    // Stop any playing audio if switching models
    if (synth.isPlaying) {
        synth.stopPlayback();
    }
    
    // Reset MIDI controls
    replayButton.disabled = true;
    downloadMidiBtn.disabled = true;
    loopCheckbox.checked = false;
    
    // Set the system prompt specific to the model type
    conversationHistory = [{
        role: 'system',
        content: modelType === 'midijourney' ? midijourneySystemPrompt : systemMessage.content
    }];

    chatOutput.innerHTML += `<p><em>Switched to ${textModel.value} model. ${modelType === 'midijourney' ? 'Starting Midjourney context...' : 'Starting new conversation with system context.'}</em></p>`;
    scrollToBottom();
});


async function generateImageFromPrompt(prompt, appendToChat = true) {
    const selectedModel = imageModel.value;
    const randomSeed = Math.floor(Math.random() * 2147483647);
    const selectedRatio = aspectRatio.value;

    // Calculate dimensions based on selected ratio
    let width = 1024;
    let height = 1024;
    let cssClass = 'square';
    
    switch(selectedRatio) {
        case '16:9':
            width = 1024;
            height = 576;
            cssClass = 'landscape';
            break;
        case '4:3':
            width = 1024;
            height = 768;
            cssClass = 'landscape';
            break;
        case '3:4':
            width = 768;
            height = 1024;
            cssClass = 'portrait';
            break;
        default: // 1:1 square
            width = 1024;
            height = 1024;
            cssClass = 'square';
    }

    const imageUrl = `https://image.pollinations.ai/prompt/${encodeURIComponent(prompt)}?seed=${randomSeed}&model=${selectedModel}&width=${width}&height=${height}&nofeed=true&nologo=true&enhance=false`;

    try {
        const response = await fetch(imageUrl);
        if (response.ok) {
            const imageBlob = await response.blob();
            const imageObjectURL = URL.createObjectURL(imageBlob);

            if (appendToChat) {
                chatOutput.innerHTML += `<img src="${imageObjectURL}" alt="Generated Image" class="inline ${cssClass}">`;
                scrollToBottom();
            }
            return imageObjectURL;
        } else {
            throw new Error('Image generation failed');
        }
    } catch (error) {
        console.error("Error generating image:", error);
        chatOutput.innerHTML += `<p><strong>Error:</strong> Unable to generate image. Please try again.</p>`;
        scrollToBottom();
    }
}

chatForm.onsubmit = async function(event) {
    event.preventDefault();

    const prompt = userInput.value.trim();
    if (!prompt) return;

    const selectedModel = textModel.value;
    const isEvil = selectedModel === 'evil';
    const modelType = getModelType(selectedModel);

    chatOutput.innerHTML += `<p><strong>${isEvil ? 'Evil User' : 'User'}:</strong> ${prompt}</p>`;
    userInput.value = '';
    scrollToBottom();

    if (modelType === 'chat' || isEvil) {
        conversationHistory.push({ role: 'user', content: prompt });
    }

    // Stop any playing audio
    if (synth.isPlaying) {
        synth.stopPlayback();
    }
    if (loopCheckbox.checked) {
        synth.stopPlayback();
    }

    const requestBody = {
        messages: getModelMessages(modelType, prompt),
        model: selectedModel
    };

    chatOutput.innerHTML += `<p id="ai-thinking"><em>${isEvil ? 'Evil AI plotting...' : 'AI is thinking...'}</em></p>`;
    scrollToBottom();

    try {
        const response = await fetch('https://text.pollinations.ai/', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            throw new Error('API request failed');
        }

        const textResponse = await response.text();
        let aiResponse = textResponse;

        // Remove thinking message
        const thinkingMessage = document.getElementById("ai-thinking");
        if (thinkingMessage) {
            thinkingMessage.remove();
        }

        // Handle MIDI and image generation
        if (aiResponse.includes("![") && aiResponse.includes("](")) {
            const promptMatch = aiResponse.match(/\!\[([^\]]*?)\]\(([^)]+)\)/);
            
            if (promptMatch) {
                lastImagePrompt = promptMatch[2];
                
                // Extract and debug MIDI data first
                console.log("\n=== STARTING MIDI PROCESSING ===");
                const midiNotation = debugMidiResponse(aiResponse);

                // Clean up the response text
                aiResponse = aiResponse
                    .replace(/!\[[^\]]*?\]\([^)]+\)[.\s]*/g, '')
                    .replace(/notation: \|-[\s\S]*?(\n\n|$)/g, '')
                    .replace(/```\npitch,time,duration,velocity\n[\s\S]*?```/g, '')
                    .trim();
                aiResponse = aiResponse.replace(/\n+/g, '\n').trim();

                // Display cleaned response text
                if (aiResponse) {
                    chatOutput.innerHTML += `<p><strong>${isEvil ? 'Evil AI' : 'AI'}:</strong> ${aiResponse}</p>`;
                    scrollToBottom();
                }

                // Handle image generation
                chatOutput.innerHTML += `<p>${isEvil ? 'Summoning evil image...' : 'Generating image...'}</p>`;
                scrollToBottom();
                await generateImageFromPrompt(lastImagePrompt);
                
                // Handle MIDI playback if available
                if (midiNotation && modelType === 'midijourney') {
                    console.log("\n=== PLAYING MIDI SEQUENCE ===");
                    console.log("MIDI Notation:", midiNotation);
                    chatOutput.innerHTML += `<p>Playing musical sequence...</p>`;
                    scrollToBottom();
                    
                    // Enable download button
                    downloadMidiBtn.disabled = false;
                    
                    // Play the sequence
                    synth.playMidiSequence(midiNotation);
                } else {
                    // Disable MIDI controls if no MIDI data
                    downloadMidiBtn.disabled = true;
                    replayButton.disabled = true;
                }
            }
        } else if (isEvil) {
            aiResponse = aiResponse.replace(/\n+/g, '\n').trim();
            chatOutput.innerHTML += `<p><strong>Evil AI:</strong> ${aiResponse}</p>`;
            chatOutput.innerHTML += `<p><em>Evil AI failed to use proper image format. Next response should include ![MRKDWN]()</em></p>`;
            scrollToBottom();
        } else {
            aiResponse = aiResponse.replace(/\n+/g, '\n').trim();
            chatOutput.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
            scrollToBottom();
        }

        // Update conversation history
        if (modelType === 'chat' || isEvil) {
            conversationHistory.push({ role: 'assistant', content: aiResponse });
            if (conversationHistory.length > (isEvil ? 8 : 20)) {
                conversationHistory = [
                    isEvil ? { role: 'system', content: evilSystemPrompt } : systemMessage,
                    ...conversationHistory.slice(-(isEvil ? 6 : 19))
                ];
            }
        }

    } catch (error) {
        console.error("Error:", error);
        const errorMessage = isEvil ? 'The darkness is temporarily unavailable. Please try again.' : 'Unable to contact AI. Please try again.';
        chatOutput.innerHTML += `<p><strong>Error:</strong> ${errorMessage}</p>`;
        scrollToBottom();
        
        const thinkingMessage = document.getElementById("ai-thinking");
        if (thinkingMessage) {
            thinkingMessage.remove();
        }
    }
};

directImageButton.onclick = async function() {
    const prompt = userInput.value.trim();
    if (!prompt && !lastImagePrompt) return;
    
    const rawPrompt = prompt || lastImagePrompt;
    lastImagePrompt = rawPrompt;
    
    chatOutput.innerHTML += `<p>${textModel.value === 'evil' ? 'Summoning evil direct image...' : 'Generating direct image...'}</p>`;
    scrollToBottom();  // Add this line right after the message is added
    
    await generateImageFromPrompt(rawPrompt);
    userInput.value = '';
};
</script>
      <!-- Footer with Pollinations.ai attribution -->
    <div style="text-align: right; margin-top: 20px; font-size: 8px; color: #aaa;">
        <a href="https://pollinations.ai" target="_blank" style="color: #aaa; text-decoration: none;">
            Generations by Pollinations.ai
        </a>
    </div>
</body>
</html>
