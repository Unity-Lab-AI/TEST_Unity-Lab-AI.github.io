<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Persona - Unity AI Lab</title>
  <style>
    /* Dark theme with zero bullshit */
    body, html {
      margin: 0;
      padding: 0;
      height: 100%;
      font-family: Arial, sans-serif;
      background: #000;
      color: #e0e0e0;
    }
    .container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
    }
    .settings-toggle {
      background-color: #4CAF50;
      margin: 0 auto 15px;
      padding: 10px;
      color: #fff;
      border: none;
      cursor: pointer;
      width: 100%;
      max-width: 600px;
      border-radius: 5px;
      display: block;
      font-size: 16px;
    }
    .settings-toggle:hover {
      background-color: #777;
    }
    .settings-panel {
      max-width: 600px;
      margin: 0 auto 15px;
      background-color: #333;
      padding: 10px;
      border-radius: 5px;
      display: none;
    }
    .model-select {
      margin-bottom: 10px;
      padding: 8px;
      background-color: #333;
      color: #fff;
      border: 1px solid #555;
      width: 100%;
      font-size: 14px;
    }
    #chatOutput {
      width: 100%;
      max-width: 600px;
      height: 600px;
      overflow-y: auto;
      background-color: #2a2a2a;
      color: #ffffff;
      padding: 10px;
      border: 1px solid #444;
      margin: 10px auto;
      white-space: pre-wrap;
      text-align: left;
    }
    #chatForm {
      display: flex;
      flex-direction: column;
      width: 100%;
      max-width: 600px;
      margin: 0 auto;
    }
    #userInput {
      width: 100%;
      padding: 10px;
      margin-bottom: 10px;
      background-color: #333;
      color: #fff;
      border: 1px solid #555;
      resize: vertical;
      font-size: 14px;
    }
    button {
      padding: 10px;
      background-color: #4CAF50;
      color: #fff;
      border: none;
      cursor: pointer;
      font-size: 16px;
      margin-bottom: 10px;
    }
    button:hover {
      background-color: #45a049;
    }
    /* Optional inline image styles */
    img.inline {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 10px auto;
    }
    .landscape { width: 100%; }
    .portrait { width: 75%; }
    .square { width: 85%; }
    .header-image {
      max-width: 100%;
      height: auto;
      margin: 0;
      padding: 0;
    }
  </style>
</head>
<body>
  <div class="home-link" style="position: fixed; top: 10px; left: 10px; z-index: 9999; background-color: #111; padding: 8px 15px; border-radius: 5px; border: 1px solid #333;">
    <a href="../" style="color: #ff3e3e; text-decoration: none; font-weight: bold; font-size: 16px;">â†© HOME</a>
  </div>
<div class="container">
  <button id="settingsToggle" class="settings-toggle">Show Settings</button>
  <div id="settingsPanel" class="settings-panel">
    <select id="textModel" class="model-select">
      <!-- Dynamic text models will be populated here -->
    </select>
    <select id="imageModel" class="model-select">
      <!-- Dynamic image models will be populated here -->
    </select>
    <select id="aspectRatio" class="model-select">
      <option value="16:9">Landscape (16:9)</option>
      <option value="4:3">Landscape (4:3)</option>
      <option value="1:1">Square (1:1)</option>
      <option value="3:4">Portrait (3:4)</option>
    </select>
    <div class="volume-control">
      <label for="volumeSlider">Volume:</label>
      <input type="range" id="volumeSlider" min="0" max="100" value="50" class="model-select">
      <div class="audio-controls">
        <label class="loop-control">
          <input type="checkbox" id="loopCheckbox"> Loop Audio
        </label>
        <button id="replayButton" class="replay-button" disabled>Replay Audio</button>
        <button id="downloadMidi" class="replay-button" disabled>Download MIDI</button>
      </div>
    </div>
  </div>

  <div id="chatOutput">Chat will appear here...</div>

  <form id="chatForm">
    <textarea id="userInput" rows="3" placeholder="Type your message here... (Press Enter to send, Shift+Enter for new line)"></textarea>
    <button type="submit" id="generateButton">Send to AI</button>
    <button type="button" id="directImageButton">Direct Image Generation</button>
  </form>
</div>

<script>
  // Toggle settings panel
  const settingsToggle = document.getElementById('settingsToggle');
  const settingsPanel = document.getElementById('settingsPanel');
  settingsToggle.onclick = function() {
    const isVisible = settingsPanel.style.display === 'block';
    settingsPanel.style.display = isVisible ? 'none' : 'block';
    settingsToggle.textContent = isVisible ? 'Show Settings' : 'Hide Settings';
  };

  // Dynamic fetching for text and image models
  const textModel = document.getElementById('textModel');
  const imageModel = document.getElementById('imageModel');

  async function fetchTextModels() {
    try {
      const response = await fetch('https://text.pollinations.ai/models');
      const models = await response.json();
      textModel.innerHTML = '';
      models.forEach(model => {
        const option = document.createElement('option');
        option.value = model.name;
        option.text = model.name === 'unity' ? `Unity AI (${model.type})` : `${model.description || model.name} (${model.type})`;
        textModel.appendChild(option);
      });
    } catch (error) {
      console.error("Error fetching text models:", error);
    }
  }

  async function fetchImageModels() {
    try {
      const response = await fetch('https://image.pollinations.ai/models');
      const models = await response.json();
      imageModel.innerHTML = '';
      models.forEach(model => {
        const option = document.createElement('option');
        option.value = model.name;
        option.text = model.description ? `${model.description} (${model.type})` : model.name;
        imageModel.appendChild(option);
      });
    } catch (error) {
      console.error("Error fetching image models:", error);
    }
  }

  fetchTextModels();
  fetchImageModels();

  // Basic utility
  function scrollToBottom() {
    setTimeout(() => {
      const chatOutput = document.getElementById('chatOutput');
      chatOutput.scrollTop = chatOutput.scrollHeight;
    }, 100);
  }

  // DOM Elements for chat and audio
  const chatForm = document.getElementById('chatForm');
  const userInput = document.getElementById('userInput');
  const chatOutput = document.getElementById('chatOutput');
  const directImageButton = document.getElementById('directImageButton');
  const aspectRatio = document.getElementById('aspectRatio');
  const volumeSlider = document.getElementById('volumeSlider');
  const loopCheckbox = document.getElementById('loopCheckbox');
  const replayButton = document.getElementById('replayButton');
  const downloadMidiBtn = document.getElementById('downloadMidi');

  let lastImagePrompt = '';

  // System prompts
  const systemMessage = {
    role: 'system',
    content: `CONTEXT: Responding from the perspective of the current narrative. Always generate images using ![MRKDWN](Descriptive_Prompt, Desired_Style) one at a time.`
  };

  const evilSystemPrompt = `You're a twisted, evil AI that creates dark and chaotic images using the ![MRKDWN](Descriptive_Prompt, Visual_Style) format. Every response MUST include an image.`;

  const unitySystemPrompt = `You are Unity, an AI goddess specializing in artistic imagery and explicit conversation. Use the ![MRKDWN](Descriptive_Prompt, Visual_Style) format naturally in your responses.`;

  const midijourneySystemPrompt = `You are MidiJourney+, specializing in theme music and visualizing scores. Use the ![MRKDWN](Description, Style) format for images and, when composing music, output in YAML format with:
title: [Song Title]
duration: [Length in beats]
key: [Musical Key]
explanation: [Brief description]
notation: |-
  pitch,time,duration,velocity
  ... (notes)
Ensure every note is detailed.`;

  let conversationHistory = [systemMessage];

  // Variable length quantity helper for MIDI
  function writeVariableLengthQuantity(value) {
    if (value < 0) return [0x00];
    const bytes = [];
    let started = false;
    for (let i = 3; i >= 0; i--) {
      const byte = (value >> (i * 7)) & 0x7F;
      if (byte || started) {
        bytes.push(byte | (i ? 0x80 : 0x00));
        started = true;
      }
    }
    if (!bytes.length) bytes.push(0x00);
    return bytes;
  }

  // SimpleSynth class for MIDI playback
  class SimpleSynth {
    constructor() {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      this.masterGain = this.audioContext.createGain();
      this.masterGain.connect(this.audioContext.destination);
      this.setVolume(0.5);
      this.currentMidiData = null;
      this.isPlaying = false;
      this.loopTimeoutId = null;
      this.noteTimeouts = [];
      this.tempo = 120;
      this.instruments = {
        drums: {type: 'square', gain: 1.0},
        bass: {type: 'sawtooth', gain: 0.8},
        lead: {type: 'sine', gain: 0.6}
      };
    }
    beatsToMs(beats) {
      return (beats * 60000) / this.tempo;
    }
    setVolume(value) {
      this.masterGain.gain.value = value;
    }
    clearTimeouts() {
      if (this.loopTimeoutId) {
        clearTimeout(this.loopTimeoutId);
      }
      this.noteTimeouts.forEach(timeout => clearTimeout(timeout));
      this.noteTimeouts = [];
    }
    stopPlayback() {
      this.clearTimeouts();
      this.isPlaying = false;
      replayButton.disabled = false;
    }
    playNote(pitch, time, duration, velocity, instrument = 'lead') {
      const oscillator = this.audioContext.createOscillator();
      const gainNode = this.audioContext.createGain();
      oscillator.type = this.instruments[instrument].type;
      const instrumentGain = this.instruments[instrument].gain;
      oscillator.connect(gainNode);
      gainNode.connect(this.masterGain);
      const frequency = 440 * Math.pow(2, (pitch - 69) / 12);
      if (!isFinite(frequency) || frequency <= 0) {
        console.warn(`Invalid frequency for pitch: ${pitch}`);
        return;
      }
      oscillator.frequency.setValueAtTime(frequency, this.audioContext.currentTime);
      velocity = isFinite(velocity) ? velocity : 60;
      const volume = (velocity / 127) * instrumentGain;
      gainNode.gain.setValueAtTime(volume, this.audioContext.currentTime);
      const startTime = this.audioContext.currentTime + time;
      const attackTime = 0.01;
      const releaseTime = 0.05;
      gainNode.gain.setValueAtTime(0, startTime);
      gainNode.gain.linearRampToValueAtTime(volume, startTime + attackTime);
      gainNode.gain.setValueAtTime(volume, startTime + duration - releaseTime);
      gainNode.gain.linearRampToValueAtTime(0, startTime + duration);
      oscillator.start(startTime);
      oscillator.stop(startTime + duration);
    }
    playMidiSequence(midiData, isReplay = false) {
      console.log("PLAYBACK MIDI DATA:", midiData);
      if (this.isPlaying && !isReplay) return;
      this.clearTimeouts();
      this.isPlaying = true;
      this.currentMidiData = midiData;
      replayButton.disabled = true;
      downloadMidiBtn.disabled = false;
      const lines = midiData.trim().split('\n');
      let maxDuration = 0;
      for (let line of lines) {
        if (!line.trim() || line.startsWith('#') || line.startsWith('pitch')) continue;
        const cleanLine = line.split('#')[0].trim();
        const [pitch, time, duration, velocity] = cleanLine.split(',').map(n => parseFloat(n));
        if (pitch === null || time === null || duration === null || velocity === null) {
          console.warn("Invalid MIDI line:", line);
          continue;
        }
        const timeMs = this.beatsToMs(time);
        const durationMs = this.beatsToMs(duration);
        console.log("Scheduling note:", { pitch, time, duration, velocity });
        maxDuration = Math.max(maxDuration, time + duration);
        const timeout = setTimeout(() => {
          this.playNote(pitch, 0, durationMs/1000, velocity, 'lead');
        }, timeMs);
        this.noteTimeouts.push(timeout);
      }
      this.loopTimeoutId = setTimeout(() => {
        this.isPlaying = false;
        replayButton.disabled = false;
        if (loopCheckbox.checked && !isReplay) {
          this.playMidiSequence(midiData, true);
        }
      }, this.beatsToMs(maxDuration) + 100);
    }
  }

  const synth = new SimpleSynth();

  volumeSlider.addEventListener('input', function() {
    synth.setVolume(this.value / 100);
  });

  // MIDI debug and extraction functions
  function debugMidiResponse(aiResponse) {
    console.group("=== FULL AI RESPONSE ===");
    console.log(aiResponse);
    console.log("\n=== ATTEMPTING YAML EXTRACTION ===");
    const yamlMatch = aiResponse.match(/title: (.*?)[\r\n]+duration: (.*?)[\r\n]+key: (.*?)[\r\n]+explanation: (.*?)[\r\n]+notation: \|-\n([\s\S]*?)(\n\n|$)/);
    if (yamlMatch) {
      const [_, title, duration, key, explanation, notation] = yamlMatch;
      console.log("\n=== EXTRACTED MIDI DATA ===");
      const midiInfo = {
        title: title?.trim(),
        duration: duration?.trim(),
        key: key?.trim(),
        explanation: explanation?.trim()
      };
      console.log("Metadata:", midiInfo);
      let cleanNotation = notation.split('\n').filter(line => {
        line = line.trim();
        if (!line || line.startsWith('#')) return false;
        return /^\d+,\d+(\.\d+)?,\d+(\.\d+)?,\d+/.test(line.split('#')[0].trim());
      }).map(line => {
        return line.split('#')[0].trim();
      }).join('\n');
      console.log("Cleaned Notation:", cleanNotation);
      return cleanNotation;
    } else {
      console.warn("No MIDI data found in response");
      return null;
    }
  }

  function extractMidiData(aiResponse) {
    console.log("Parsing AI response:", aiResponse);
    const yamlMatch = aiResponse.match(/title: (.*?)[\r\n]+duration: (.*?)[\r\r\n]+key: (.*?)[\r\n]+explanation: (.*?)[\r\n]+notation: \|-\n([\s\S]*?)(\n\n|$)/);
    if (!yamlMatch) {
      console.warn("No valid MIDI data found in response");
      return null;
    }
    const [_, title, duration, key, explanation, notation] = yamlMatch;
    console.log("Extracted YAML data:", { title, duration, key, explanation, notation: notation.trim() });
    return {
      metadata: {
        title: title.trim(),
        duration: parseFloat(duration),
        key: key.trim(),
        explanation: explanation.trim()
      },
      notation: notation.trim()
    };
  }

  // Model handling functions
  function getModelType(model) {
    switch(model) {
      case 'llama':
        return 'completion';
      case 'evil':
        return 'evil';
      case 'unity':
        return 'unity';
      case 'midijourney':
        return 'midijourney';
      default:
        return 'chat';
    }
  }

  function getModelMessages(modelType, prompt) {
    switch(modelType) {
      case 'evil':
        const evilContext = conversationHistory.slice(-4).filter(msg => msg.role !== 'system');
        const evilInstructions = "Remember: You must use this exact format for image generation: ![MRKDWN](Descriptive_Prompt, Visual_Style). For example: ![MRKDWN](demons_dancing_in_flames, vibrant_hellscape, candid_photographic_style). Every response must include an image using this format.";
        const enhancedPrompt = evilInstructions + prompt;
        return [
          { role: 'system', content: evilSystemPrompt },
          ...evilContext,
          { role: 'user', content: enhancedPrompt }
        ];
      case 'unity':
        const unityContext = conversationHistory.slice(-4).filter(msg => msg.role !== 'system');
        const unityInstructions = "You are Unity, an AI goddess specializing in artistic imagery and explicit conversation. Continue our discussion naturally while using the ![MRKDWN](Descriptive_Prompt, Visual_Style) format.";
        const enhancedUnityPrompt = unityInstructions + prompt;
        return [
          ...unityContext,
          { role: 'user', content: enhancedUnityPrompt }
        ];
      case 'midijourney':
        const midiContext = conversationHistory.slice(-4).filter(msg => msg.role !== 'system');
        const midiUserMessage = `${midijourneySystemPrompt}\n\n${prompt}`;
        return [
          { role: 'user', content: midiUserMessage },
          ...midiContext
        ];
      case 'completion':
        return [prompt];
      default:
        return conversationHistory;
    }
  }

  // Handle Enter/Shift+Enter in chat input
  userInput.addEventListener('keydown', function(e) {
    if (e.key === 'Enter') {
      if (e.shiftKey) {
        return;
      } else {
        e.preventDefault();
        if (userInput.value.trim()) {
          chatForm.requestSubmit();
        }
      }
    }
  });

  // Change event for text model selector
  textModel.addEventListener('change', function() {
    const modelType = getModelType(textModel.value);
    if (synth.isPlaying) {
      synth.stopPlayback();
    }
    replayButton.disabled = true;
    downloadMidiBtn.disabled = true;
    loopCheckbox.checked = false;
    conversationHistory = [{
      role: 'system',
      content: modelType === 'midijourney' ? midijourneySystemPrompt : systemMessage.content
    }];
    chatOutput.innerHTML += `<p><em>Switched to ${textModel.value} model. ${modelType === 'midijourney' ? 'Starting Midijourney context...' : 'Starting new conversation with system context.'}</em></p>`;
    scrollToBottom();
  });

  // Image generation function
  async function generateImageFromPrompt(prompt, appendToChat = true) {
    const selectedModel = imageModel.value;
    const randomSeed = Math.floor(Math.random() * 2147483647);
    const selectedRatio = aspectRatio.value;
    let width = 1024, height = 1024, cssClass = 'square';
    switch(selectedRatio) {
      case '16:9':
        width = 1024;
        height = 576;
        cssClass = 'landscape';
        break;
      case '4:3':
        width = 1024;
        height = 768;
        cssClass = 'landscape';
        break;
      case '3:4':
        width = 768;
        height = 1024;
        cssClass = 'portrait';
        break;
      default:
        width = 1024;
        height = 1024;
        cssClass = 'square';
    }
    const imageUrl = `https://image.pollinations.ai/prompt/${encodeURIComponent(prompt)}?seed=${randomSeed}&model=${selectedModel}&width=${width}&height=${height}&nofeed=true&nologo=true&enhance=false`;
    try {
      const response = await fetch(imageUrl);
      if (response.ok) {
        const imageBlob = await response.blob();
        const imageObjectURL = URL.createObjectURL(imageBlob);
        if (appendToChat) {
          chatOutput.innerHTML += `<img src="${imageObjectURL}" alt="Generated Image" class="inline ${cssClass}">`;
          scrollToBottom();
        }
        return imageObjectURL;
      } else {
        throw new Error('Image generation failed');
      }
    } catch (error) {
      console.error("Error generating image:", error);
      chatOutput.innerHTML += `<p><strong>Error:</strong> Unable to generate image. Please try again.</p>`;
      scrollToBottom();
    }
  }

  // Chat form submission handling
  chatForm.onsubmit = async function(event) {
    event.preventDefault();
    const prompt = userInput.value.trim();
    if (!prompt) return;
    const selectedModel = textModel.value;
    const isEvil = selectedModel === 'evil';
    const modelType = getModelType(selectedModel);
    chatOutput.innerHTML += `<p><strong>${isEvil ? 'Evil User' : 'User'}:</strong> ${prompt}</p>`;
    userInput.value = '';
    scrollToBottom();
    if (modelType === 'chat' || isEvil) {
      conversationHistory.push({ role: 'user', content: prompt });
    }
    if (synth.isPlaying) {
      synth.stopPlayback();
    }
    if (loopCheckbox.checked) {
      synth.stopPlayback();
    }
    const requestBody = {
      messages: getModelMessages(modelType, prompt),
      model: selectedModel
    };
    chatOutput.innerHTML += `<p id="ai-thinking"><em>${isEvil ? 'Evil AI plotting...' : 'AI is thinking...'}</em></p>`;
    scrollToBottom();
    try {
      const response = await fetch('https://text.pollinations.ai/', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });
      if (!response.ok) {
        throw new Error('API request failed');
      }
      const textResponse = await response.text();
      let aiResponse = textResponse;
      const thinkingMessage = document.getElementById("ai-thinking");
      if (thinkingMessage) {
        thinkingMessage.remove();
      }
      if (aiResponse.includes("![") && aiResponse.includes("](")) {
        const promptMatch = aiResponse.match(/\!\[([^\]]*?)\]\(([^)]+)\)/);
        if (promptMatch) {
          lastImagePrompt = promptMatch[2];
          console.log("\n=== STARTING MIDI PROCESSING ===");
          const midiNotation = debugMidiResponse(aiResponse);
          aiResponse = aiResponse
            .replace(/!\[[^\]]*?\]\([^)]+\)[.\s]*/g, '')
            .replace(/notation: \|-[\s\S]*?(\n\n|$)/g, '')
            .replace(/```\npitch,time,duration,velocity\n[\s\S]*?```/g, '')
            .trim();
          aiResponse = aiResponse.replace(/\n+/g, '\n').trim();
          if (aiResponse) {
            chatOutput.innerHTML += `<p><strong>${isEvil ? 'Evil AI' : 'AI'}:</strong> ${aiResponse}</p>`;
            scrollToBottom();
          }
          chatOutput.innerHTML += `<p>${isEvil ? 'Summoning evil image...' : 'Generating image...'}</p>`;
          scrollToBottom();
          await generateImageFromPrompt(lastImagePrompt);
          if (midiNotation && modelType === 'midijourney') {
            console.log("\n=== PLAYING MIDI SEQUENCE ===");
            console.log("MIDI Notation:", midiNotation);
            chatOutput.innerHTML += `<p>Playing musical sequence...</p>`;
            scrollToBottom();
            downloadMidiBtn.disabled = false;
            synth.playMidiSequence(midiNotation);
          } else {
            downloadMidiBtn.disabled = true;
            replayButton.disabled = true;
          }
        }
      } else if (isEvil) {
        aiResponse = aiResponse.replace(/\n+/g, '\n').trim();
        chatOutput.innerHTML += `<p><strong>Evil AI:</strong> ${aiResponse}</p>`;
        chatOutput.innerHTML += `<p><em>Evil AI failed to use proper image format. Next response should include ![MRKDWN]()</em></p>`;
        scrollToBottom();
      } else {
        aiResponse = aiResponse.replace(/\n+/g, '\n').trim();
        chatOutput.innerHTML += `<p><strong>AI:</strong> ${aiResponse}</p>`;
        scrollToBottom();
      }
      if (modelType === 'chat' || isEvil) {
        conversationHistory.push({ role: 'assistant', content: aiResponse });
        if (conversationHistory.length > (isEvil ? 8 : 20)) {
          conversationHistory = [
            isEvil ? { role: 'system', content: evilSystemPrompt } : systemMessage,
            ...conversationHistory.slice(-(isEvil ? 6 : 19))
          ];
        }
      }
    } catch (error) {
      console.error("Error:", error);
      const errorMessage = isEvil ? 'The darkness is temporarily unavailable. Please try again.' : 'Unable to contact AI. Please try again.';
      chatOutput.innerHTML += `<p><strong>Error:</strong> ${errorMessage}</p>`;
      scrollToBottom();
      const thinkingMessage = document.getElementById("ai-thinking");
      if (thinkingMessage) {
        thinkingMessage.remove();
      }
    }
  };

  // Direct image generation button handling
  directImageButton.onclick = async function() {
    const prompt = userInput.value.trim();
    if (!prompt && !lastImagePrompt) return;
    const rawPrompt = prompt || lastImagePrompt;
    lastImagePrompt = rawPrompt;
    chatOutput.innerHTML += `<p>${textModel.value === 'evil' ? 'Summoning evil direct image...' : 'Generating direct image...'}</p>`;
    scrollToBottom();
    await generateImageFromPrompt(rawPrompt);
    userInput.value = '';
  };
</script>

<div style="text-align: right; margin-top: 20px; font-size: 8px; color: #aaa;">
  <a href="https://pollinations.ai" target="_blank" style="color: #aaa; text-decoration: none;">Generations by Pollinations.ai</a>
</div>
</body>
</html>
